{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model 1 Code: This is the model we started with to tune the hyperparamters using RandomizedSearchCV which uses TimesSeriesSplits\n",
    "\n",
    "### WARNING - please place the file in the same directory as the dataset csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "data = pd.read_csv('Products_Information.csv')\n",
    "\n",
    "# as the date is an 'object', changing it into datetime64(ms) format\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# setting the date as index\n",
    "data.set_index('date', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['sales'] <= 40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extracting date features from date index and label encoding the necessary ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breaking the date into day_of_week, month and day_of_month\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "data['month'] = data.index.month\n",
    "data['day_of_month'] = data.index.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing our data into a new variable \n",
    "data_encoded = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lagged Feature and Rolling Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lagged feature capturing the sales data of the previous week's same day\n",
    "data_encoded['sales_lag_7'] = data_encoded.groupby(['store_nbr', 'product_type'])['sales'].shift(7)\n",
    "\n",
    "# rolling windows \n",
    "data_encoded['rolling_window_7_skew'] = data_encoded.groupby(['store_nbr', 'product_type'])['sales'].shift(1).rolling(window=7).skew()\n",
    "\n",
    "data_encoded['rolling_window_7_std'] = data_encoded.groupby(['store_nbr', 'product_type'])['sales'].shift(1).rolling(window=7).std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding product_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "data_encoded['product_type'] = label_encoder.fit_transform(data['product_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing the ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the id column for preparation of training and prediction datasets\n",
    "data_encoded = data_encoded.drop('id',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into training and predictions\n",
    "\n",
    "training_data = data_encoded['2016-01-01':'2017-07-30']\n",
    "\n",
    "prediction_data = data_encoded['2017-07-31':'2017-08-15']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HISTGRADIENTBOOSTING REGRESSOR MODEL with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Search took 10.49 seconds.\n",
      "\n",
      "\n",
      "Best Hyperparameters: {'min_samples_leaf': 30, 'max_depth': 2, 'learning_rate': 0.05, 'l2_regularization': 0.9}\n",
      "RMSE for this fold: 264.62214463678424\n",
      "RMSE for this fold: 436.1347069204234\n",
      "RMSE for this fold: 342.60561933542044\n"
     ]
    }
   ],
   "source": [
    "# Separating the dataset into input and output arrays.\n",
    "X = training_data.drop(['sales'], axis=1)\n",
    "y = training_data['sales']\n",
    "\n",
    "# Implementing Time Series Split with 3 splits\n",
    "tscv = TimeSeriesSplit(n_splits=3)  \n",
    "\n",
    "# Defining the parameter grid for randomized search\n",
    "param_grid = {\n",
    "    'max_depth': [1,2,3],\n",
    "    'learning_rate': [0.01,0.02, 0.03,0.04,0.05],\n",
    "    'min_samples_leaf': [30,40,60],\n",
    "    'l2_regularization': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Creating HGBR Model 1 (worst performing model)\n",
    "model = HistGradientBoostingRegressor(random_state=20, categorical_features = ['day_of_week', 'month', 'day_of_month','store_nbr', 'product_type'])\n",
    "\n",
    "# Creating RandomizedSearch CV grid\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_grid,n_iter=10, scoring='neg_root_mean_squared_error',random_state=20,cv=tscv, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create a list to score the scores for each fold\n",
    "rmse_scores = []\n",
    "\n",
    "# Measuring run time for Cross Validation\n",
    "start_time = time.time()\n",
    "\n",
    "# Performing RandomizedSearchCV using Time Series split to separate training and validation sets.\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Storing the best model from  random search CV\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "\n",
    "# Print the run time for random search CV\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Randomized Search took {elapsed_time:.2f} seconds.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the best hyperparameters from the randomized search CV\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "# Printing the performance of the best model on each TimeSeriesSplit to measure performance across folds\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    \n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    print(f\"RMSE for this fold: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF FILE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
